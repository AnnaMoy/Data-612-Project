---
title: "Data 613 - Project 1"
author: "Anna Moy & Natalie Kalukeerthie"
date: "2025-06-08"
output: html_document
---



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# Load library
library(reshape2)
```

# Overview

Briefly describe the recommender system that you’re going to build out from a business
perspective, e.g. “This system recommends data science books to readers.”

For this project, we will be building a system where Yelp users leave ratings (from 1 to 5) on restaurants they've visited. However, no user reviews every restaurant. Our recommender system will estimate missing ratings using average scores and bias adjustments — helping us to figure out which restaurants most users liked.


We simulate reviews from 6 Yelp users (Alice, Ben, Cindy, David, Ella, Frank) for 5 restaurants (Pasta Place, Sushi Spot, Burger Barn, Curry Corner, Taco Town). Some users have not rated every restaurant.

```{r}
# Create Dataset with 6 users and 5 restaurants
ratings_df <- data.frame(
  user = c(
    rep("Alice", 5),
    rep("Ben", 5),
    rep("Cindy", 5),
    rep("David", 5),
    rep("Ella", 5),
    rep("Frank", 5)
  ),
  restaurant = rep(c("Pasta_Place", "Sushi_Spot", "Burger_Barn", "Curry_Corner", "Taco_Town"), 6),
  rating = c(
    5, NA, 4, NA, 4,      # Alice
    4, 3, 5, 3, 4,        # Ben
    4, 2, NA, NA, 3,      # Cindy
    2, 2, 3, 1, 2,        # David
    4, NA, 5, 4, 5,       # Ella
    4, 2, 5, 4, 4         # Frank
  )
)

ratings_df
```

```{r}
#Transform data frame into a user-item matrix

#pivot the long format into a matrix for user, item and ratings
matrix <- dcast(ratings_df, user ~ restaurant, value.var = "rating") 

# row labels will be the based on user
rownames(matrix) <- matrix$user

# remove the first column since it is repeating duplicate value
matrix <- matrix[, -1]

#print the matrix
print(matrix)

```


```{r}
set.seed(42)
# Take the data and split into training 80% and testing 20% dataframe
train_indices <- sample(1:nrow(ratings_df), size = 0.8 * nrow(ratings_df))

train_df <- ratings_df[train_indices, ]
test_df <- ratings_df[-train_indices, ]

train_df
test_df
```


```{r}
# Find the Raw average and calculate RMSE

# Raw Average on Training set and ignore NA
global_mean <- mean(train_df$rating, na.rm = TRUE)


# Add the raw avg onto the training and test dataset
train_df$raw_avg <- global_mean
test_df$raw_avg <- global_mean

# RMSE function
rmse <- function(actual, predicted) {
  sqrt(mean((actual - predicted)^2))
}

train_fil <- train_df[!is.na(train_df$rating), ]
test_fil <- test_df[!is.na(test_df$rating), ]


# Calculate RSME which takes the difference of ratings - avg mean for training and test set
rmse_train_raw <- rmse(train_fil$rating, train_fil$raw_avg)
rmse_test_raw <- rmse(test_fil$rating, test_fil$raw_avg)

rmse_train_raw
rmse_test_raw

```

```{r}
#Finds out the bias values for all columns and rows in grid

# Find the mean for all bia users in training data
user_avg <- aggregate(rating ~ user, data = train_df, mean)
# Take the user bias values and the difference from the raw mean
user_avg$user_bias <- user_avg$rating - global_mean

user_avg

# Find the mean for all items in the training data
restaurant_avg <- aggregate(rating ~ restaurant, data = train_df, mean)

# Take the item values and the difference frm the raw mean
restaurant_avg$restaurant_bias <- restaurant_avg$rating - global_mean

restaurant_avg

```

```{r}
#Baseline Predictor

# Merge user bias into the training data set by user
train_df <- merge(train_df, user_avg[, c("user", "user_bias")], by = "user", all.x = TRUE)

#Merger item into the training data set by item
train_df <- merge(train_df, restaurant_avg[, c("restaurant", "restaurant_bias")], by = "restaurant", all.x = TRUE)

train_df

#Baseline Predictor for Training data avg + user bias + item bias
train_df$pred_baseline <- global_mean + train_df$user_bias + train_df$restaurant_bias

# Repeat same steps for testing dataset
test_df <- merge(test_df, user_avg[, c("user", "user_bias")], by = "user", all.x = TRUE)
test_df <- merge(test_df, restaurant_avg[, c("restaurant", "restaurant_bias")], by = "restaurant", all.x = TRUE)

test_df$pred_baseline <- global_mean + test_df$user_bias + test_df$restaurant_bias
```


```{r}
# Baseline Predictor RMSE

#remove the NA in the row
train_filtered <- train_df[!is.na(train_df$rating), ]
test_filtered <- test_df[!is.na(test_df$rating), ]

# Using the RMSE function taking the difference between rating and baseline predictor for training and test set
rmse_train_base <- rmse(train_filtered$rating, train_filtered$pred_baseline)
rmse_test_base <- rmse(test_filtered$rating, test_filtered$pred_baseline)


rmse_train_base
rmse_test_base
```

```{r}
cat("Raw Average Model:\n")
cat("  RMSE Train:", round(rmse_train_raw, 3), "\n")
cat("  RMSE Test: ", round(rmse_test_raw, 3), "\n\n")

cat("Baseline Predictor Model:\n")
cat("  RMSE Train:", round(rmse_train_base, 3), "\n")
cat("  RMSE Test: ", round(rmse_test_base, 3), "\n")


result <- ((1- rmse_test_base)/rmse_test_raw) * 100

cat("  RMSE Test Increased or Decreased: ", round(result, 3), "\n")

```
The Raw Average Model uses the overall average rating to predict user ratings, resulting in:

    Training RMSE: 1.134

    Testing RMSE: 1.183

The Baseline Predictor Model, which adjusts predictions by 

    Training RMSE: 0.549 (lower than raw average)

    Testing RMSE: 1.087 (lower than raw average)
    
The testing RMSE decreased by about 8.12% with the baseline model compared to the raw average, indicating better generalization on unseen data. 

The lower the RMSE in the baseline predictor model shows it is better than the raw average model. 
The Sushi Spot and Curry Corner shows they have lower average ratings in the training data which indicated on average users rated these below the average. Burger Barn and Taco Town on the other hand received higher average ratings from users which indicates customer satisfaction. 

The users Alice and Ella will provide higher ratings compared to others on average which are positive user biases. The negative user biases would be David and Cindy. 




